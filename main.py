import os
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import warnings
import pytz
import re

# å¿½ç•¥ InsecureRequestWarning è­¦å‘Š
from urllib3.exceptions import InsecureRequestWarning
warnings.simplefilter('ignore', InsecureRequestWarning)

# åˆå§‹åŒ– FastAPI æ‡‰ç”¨
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==============================================================================
# ===== âœ¨ è«‹å†æ¬¡ç¢ºèªæ‚¨å·²å¡«å…¥æ­£ç¢ºçš„ TDX é‡‘é‘° (ä¸¦ç”¨é›™å¼•è™ŸåŒ…èµ·ä¾†) âœ¨ =====
# ==============================================================================
TDX_APP_ID = "t1190t-cb75f4a4-e514-489f"  # è«‹æ›¿æ›æˆæ‚¨çš„ APP ID
TDX_APP_KEY = "dc00bc01-dff4-47cb-97f4-88fec81e69cc" # è«‹æ›¿æ›æˆæ‚¨çš„ APP KEY
# ==============================================================================

CWA_API_KEY = os.environ.get('CWA_API_KEY', 'CWA-B3D5458A-4530-4045-A702-27A786C1E934')
TAIPEI_TZ = pytz.timezone('Asia/Taipei')

# --- Helper Functions (ä¿æŒä¸è®Š) ---
def get_rain_level(value: float) -> tuple[str, str, str]:
    if value < 0: return "è³‡æ–™ç•°å¸¸", "rain-red", "è³‡æ–™ç•°å¸¸"
    if value > 200: return "ğŸŸ¥ è±ªå¤§é›¨", "rain-red", "è±ªå¤§é›¨"
    if value > 130: return "ğŸŸ§ è±ªé›¨", "rain-orange", "è±ªé›¨"
    if value > 80: return "ğŸŸ¨ å¤§é›¨", "rain-yellow", "å¤§é›¨"
    if value > 30: return "ğŸŸ¦ ä¸­é›¨", "rain-blue", "ä¸­é›¨"
    if value > 0: return "ğŸŸ© å°é›¨", "rain-green", "å°é›¨"
    return "â¬œï¸ ç„¡é›¨", "rain-none", "ç„¡é›¨"

# --- API è·¯ç”±å®šç¾© (ä¿æŒä¸è®Š) ---
@app.get("/api/dashboard-data")
async def get_dashboard_data() -> Dict[str, Any]:
    current_time = datetime.now(TAIPEI_TZ).strftime("%Y-%m-%d %H:%M:%S")

    rain_info = await get_cwa_rain_data()
    earthquake_info = await get_cwa_earthquake_data()
    typhoon_info = await get_cwa_typhoon_data()
    road_info = await get_suhua_road_data()

    dashboard_data = {
        "lastUpdate": current_time,
        "rainInfo": rain_info,
        "earthquakeInfo": earthquake_info,
        "roadInfo": road_info,
        "typhoonInfo": typhoon_info
    }
    return dashboard_data

# --- å…¶ä»–è³‡æ–™ç²å–å‡½å¼ (ç‚ºæ±‚ç°¡æ½”çœç•¥ï¼Œä¿æŒä¸è®Š) ---
@app.get("/api/radar-image")
async def get_radar_image():
    image_url = "https://www.cwa.gov.tw/Data/radar/CV1_3600.png"
    try:
        response = requests.get(image_url, timeout=10, verify=False)
        response.raise_for_status()
        return Response(content=response.content, media_type="image/png")
    except requests.exceptions.RequestException as e:
        print(f"Error fetching radar image: {e}")
        return Response(status_code=404)

@app.get("/api/rainfall-map")
async def get_rainfall_map():
    image_url = "https://c1.1968services.tw/map-data/O-A0040-002.jpg"
    try:
        response = requests.get(image_url, timeout=10, verify=False)
        response.raise_for_status()
        return Response(content=response.content, media_type="image/jpeg")
    except requests.exceptions.RequestException as e:
        print(f"Error fetching rainfall map: {e}")
        return Response(status_code=404)
        
async def get_cwa_rain_forecast():
    location_names = "è˜‡æ¾³é®,å—æ¾³é„‰,ç§€æ—é„‰,æ–°åŸé„‰"
    url = f"https://opendata.cwa.gov.tw/api/v1/rest/datastore/F-D0047-091?Authorization={CWA_API_KEY}&locationName={location_names}&elementName=PoP6h"
    forecasts = {}
    try:
        response = requests.get(url, verify=False, timeout=15)
        response.raise_for_status()
        data = response.json()
        locations = data.get("records", {}).get("location", [])
        for loc in locations:
            loc_name = loc.get("locationName")
            weather_elements = loc.get("weatherElement", [])
            pop6h = next((el for el in weather_elements if el.get("elementName") == "PoP6h"), None)
            if pop6h and pop6h.get("time"):
                first_forecast_pop = int(pop6h["time"][0]["parameter"]["parameterValue"])
                if first_forecast_pop <= 10:
                    forecasts[loc_name] = "ç„¡æ˜é¡¯é™é›¨"
                else:
                    forecasts[loc_name] = f"{first_forecast_pop}% æ©Ÿç‡é™é›¨"
            else:
                forecasts[loc_name] = "é å ±è³‡æ–™ç•°å¸¸"
    except requests.exceptions.RequestException as e:
        print(f"Error fetching rain forecast: {e}")
        for name in location_names.split(","):
            forecasts[name] = "é å ±è®€å–å¤±æ•—"
    return forecasts

async def get_cwa_rain_data():
    station_ids = {"C0O920": "è˜‡æ¾³é®", "C0U9N0": "å—æ¾³é„‰", "C0Z030": "ç§€æ—é„‰", "C0T8A0":"æ–°åŸé„‰"}
    forecast_data = await get_cwa_rain_forecast()
    url = f"https://opendata.cwa.gov.tw/api/v1/rest/datastore/O-A0002-001?Authorization={CWA_API_KEY}&stationId={','.join(station_ids.keys())}"
    processed_data = []
    try:
        response = requests.get(url, verify=False, timeout=15)
        response.raise_for_status()
        data = response.json()
        stations_data = {station["stationId"]: station for station in data.get("records", {}).get("location", [])}
        for station_id, station_name in station_ids.items():
            station = stations_data.get(station_id)
            if station:
                rain_value_str = next((item["elementValue"] for item in station["weatherElement"] if item["elementName"] == "HOUR_24"), "0")
                rain_value = float(rain_value_str)
                obs_time = datetime.fromisoformat(station["time"]["obsTime"]).astimezone(TAIPEI_TZ).strftime("%H:%M")
                level_text, css_class, _ = get_rain_level(rain_value)
                processed_data.append({
                    "location": station_name, "mm": rain_value, "class": css_class,
                    "level": level_text, "time": obs_time,
                    "forecast": forecast_data.get(station_name, "é å ±è®€å–å¤±æ•—")
                })
            else:
                processed_data.append({ "location": station_name, "mm": "N/A", "class": "rain-nodata", "level": "æ¸¬ç«™æš«ç„¡å›å ±", "time": "", "forecast": forecast_data.get(station_name, "N/A") })
    except requests.exceptions.RequestException as e:
        print(f"Error fetching rain data: {e}")
        for station_name in station_ids.values():
            processed_data.append({"location": station_name, "mm": "N/A", "class": "rain-error", "level": "è®€å–å¤±æ•—", "time": "", "forecast": "N/A"})
    return processed_data

async def get_cwa_earthquake_data():
    url = f"https://opendata.cwa.gov.tw/api/v1/rest/datastore/E-A0015-001?Authorization={CWA_API_KEY}&limit=30"
    processed_data = []
    try:
        response = requests.get(url, verify=False, timeout=15)
        response.raise_for_status()
        data = response.json()
        if data.get("records") and data["records"].get("Earthquake"):
            three_days_ago = datetime.now(TAIPEI_TZ) - timedelta(days=3)
            for quake in data["records"]["Earthquake"]:
                earthquake_info = quake.get("EarthquakeInfo", {})
                quake_time_str = earthquake_info.get("OriginTime")
                if not quake_time_str: continue
                quake_time = datetime.fromisoformat(quake_time_str).astimezone(TAIPEI_TZ)
                if quake_time >= three_days_ago:
                    yilan_level_str = "0"; hualien_level_str = "0"
                    for area in quake.get("Intensity", {}).get("ShakingArea", []):
                        if area.get("AreaDesc") == "å®œè˜­ç¸£": yilan_level_str = area.get("AreaIntensity", "0")
                        if area.get("AreaDesc") == "èŠ±è“®ç¸£": hualien_level_str = area.get("AreaIntensity", "0")
                    try:
                        yilan_level_int = int(yilan_level_str.replace("ç´š", "")); hualien_level_int = int(hualien_level_str.replace("ç´š", ""))
                    except ValueError:
                        yilan_level_int = 0; hualien_level_int = 0
                    if yilan_level_int >= 2 or hualien_level_int >= 2:
                        epicenter = earthquake_info.get("Epicenter", {})
                        magnitude_info = earthquake_info.get("Magnitude", {})
                        magnitude_value = magnitude_info.get("MagnitudeValue", 0)
                        report_content = quake.get("ReportContent", "")
                        report_time_str = ""
                        if isinstance(report_content, dict): report_time_str = report_content.get("web", "")
                        report_time = datetime.fromisoformat(report_time_str).astimezone(TAIPEI_TZ).strftime("%H:%M") if report_time_str else ""
                        processed_data.append({
                            "time": quake_time.strftime("%Y-%m-%d %H:%M"), "location": epicenter.get("Location", "ä¸æ˜"),
                            "magnitude": magnitude_value, "depth": earthquake_info.get("FocalDepth", 0),
                            "hualien_level": str(hualien_level_int), "yilan_level": str(yilan_level_int),
                            "data_time": report_time
                        })
    except requests.exceptions.RequestException as e:
        print(f"Error fetching earthquake data: {e}")
    return processed_data

async def get_cwa_typhoon_data():
    url = f"https://opendata.cwa.gov.tw/api/v1/rest/datastore/T-A0001-001?Authorization={CWA_API_KEY}"
    try:
        response = requests.get(url, verify=False, timeout=15)
        response.raise_for_status()
        data = response.json()
        if data.get("records") and data["records"].get("sea_typhoon_warning"):
            typhoon_warnings = data["records"]["sea_typhoon_warning"].get("typhoon_warning_summary",{}).get("SeaTyphoonWarning")
            if typhoon_warnings:
                typhoon = typhoon_warnings[0]
                update_time = datetime.fromisoformat(typhoon["issue_time"]).astimezone(TAIPEI_TZ).strftime("%H:%M")
                return {
                    "name": typhoon["typhoon_name"], "warning_type": typhoon["warning_type"],
                    "update_time": update_time, "location": typhoon["center_location"],
                    "wind_speed": typhoon["max_wind_speed"], "status": typhoon["warning_summary"]["content"],
                    "img_url": "https://www.cwa.gov.tw/Data/typhoon/TY_NEWS/TY_NEWS_0.jpg"
                }
    except requests.exceptions.RequestException as e:
        if e.response and e.response.status_code == 404:
            pass
        else:
            print(f"Error fetching typhoon data: {e}")
    return None

# ==============================================================================
# ===== âœ¨ TDX API å‡½å¼ (æœ€çµ‚æ¬Šå¨ç‰ˆï¼Œåƒç…§å®˜æ–¹æ–‡ä»¶) âœ¨ =====
# ==============================================================================
def get_tdx_access_token():
    """
    æ­¥é©Ÿ1: ç²å– TDX çš„ Access Token
    """
    auth_url = "https://tdx.transportdata.tw/auth/realms/TDXConnect/protocol/openid-connect/token"
    body = {
        "grant_type": "client_credentials",
        "client_id": TDX_APP_ID,
        "client_secret": TDX_APP_KEY,
    }
    headers = {
        "Content-Type": "application/x-www-form-urlencoded"
    }
    
    try:
        response = requests.post(auth_url, data=body, headers=headers)
        response.raise_for_status()
        token_data = response.json()
        print("âœ… æˆåŠŸç²å– TDX Access Tokenï¼")
        return token_data.get("access_token")
    except requests.exceptions.RequestException as e:
        print(f"âŒ ç²å– TDX Access Token å¤±æ•—: {e}")
        if e.response:
            print(f"    ä¼ºæœå™¨å›æ‡‰éŒ¯èª¤: {e.response.text}")
        return None

async def get_suhua_road_data() -> Dict[str, List[Dict[str, Any]]]:
    """
    æ­¥é©Ÿ2: ä½¿ç”¨ Access Token ç²å–è˜‡èŠ±å…¬è·¯è·¯æ³ï¼Œä¸¦é€²è¡Œåˆ†é¡
    """
    sections = {
        "è˜‡æ¾³-å—æ¾³": ["è˜‡æ¾³", "æ±æ¾³", "è˜‡æ¾³éš§é“", "æ±æ¾³éš§é“", "æ±å²³éš§é“"],
        "å—æ¾³-å’Œå¹³": ["å—æ¾³", "æ­¦å¡”", "æ¼¢æœ¬", "å’Œå¹³", "è§€éŸ³éš§é“", "è°·é¢¨éš§é“"],
        "å’Œå¹³-ç§€æ—": ["å’Œå¹³", "å’Œä»", "å´‡å¾·", "ç§€æ—", "å’Œå¹³éš§é“", "å’Œä¸­éš§é“", "å’Œä¸­æ©‹", "ä»æ°´éš§é“", "å¤§æ¸…æ°´éš§é“", "éŒ¦æ–‡éš§é“", "åŒ¯å¾·éš§é“", "å´‡å¾·éš§é“", "æ¸…æ°´æ–·å´–", "ä¸‹æ¸…æ°´æ©‹", "å¤§æ¸…æ°´"]
    }
    high_risk_keywords = ["å°é–‰", "ä¸­æ–·", "åæ–¹"]
    downgrade_keywords = ["æ”¹é“", "æ›¿ä»£é“è·¯", "è¡Œé§›å°9ä¸ç·š", "å–®ç·šé›™å‘", "æˆ’è­·é€šè¡Œ", "æ”¾è¡Œ"]
    mid_risk_keywords = ["è½çŸ³", "æ–½å·¥", "ç®¡åˆ¶", "äº‹æ•…", "å£…å¡", "è»Šå¤š", "æ¿ƒéœ§", "ä½œæ¥­"]
    degree_keywords = ["å–®ç·š", "å–®å´", "è»Šé“", "éå…¨è·¯å¹…", "æ…¢è»Šé“", "æ©Ÿå‹•"]
    
    results = {name: [] for name in sections.keys()}
    
    access_token = get_tdx_access_token()
    
    if not access_token:
        error_event = { "section": "å…¨ç·š", "status": "èªè­‰å¤±æ•—", "class": "road-red", "desc": "ç„¡æ³•ç²å–TDXæˆæ¬Š", "time": "", "is_old_road": False, "detail_url": "" }
        for section_name in sections.keys():
            results[section_name].append(error_event)
        return results

    # ã€æœ¬æ¬¡ä¿®æ­£é‡é»ã€‘ä½¿ç”¨æ‚¨æ‰¾åˆ°çš„ã€æœ€æ­£ç¢ºçš„ã€Œå…¬è·¯æ¶ˆæ¯ v2 APIã€è·¯å¾‘
    road_event_url = "https://tdx.transportdata.tw/api/basic/v2/Road/Traffic/News/Road/Provincial?$filter=contains(RoadName,'å°9')&$orderby=PublishTime desc&$top=50&$format=JSON"
    
    headers = {
        "Authorization": f"Bearer {access_token}"
    }

    try:
        response = requests.get(road_event_url, headers=headers, timeout=15)
        response.raise_for_status()
        
        data = response.json()
        news_items = data.get("Newses", []) # æ ¹æ“š Swaggerï¼Œv2 çš„è³‡æ–™åœ¨ "Newses" æ¬„ä½ä¸­
        
        print(f"âœ… æˆåŠŸå¾ TDX API ç²å– {len(news_items)} å‰‡è·¯æ³æ¶ˆæ¯ã€‚")

        for news in news_items:
            content = news.get("Description", "") # æè¿°æ¬„ä½æ˜¯ Description
            if not content:
                continue

            report_time = ""
            update_time_str = news.get("PublishTime") # ä½¿ç”¨ç™¼å¸ƒæ™‚é–“
            if update_time_str:
                try:
                    utc_time = datetime.fromisoformat(update_time_str.replace('Z', '+00:00'))
                    taipei_time = utc_time.astimezone(TAIPEI_TZ)
                    report_time = f"ç™¼å¸ƒæ™‚é–“: {taipei_time.strftime('%Y-%m-%d %H:%M')}"
                except (ValueError, TypeError):
                    pass

            status = "äº‹ä»¶"; css_class = "road-yellow"; is_high_risk = False
            for keyword in high_risk_keywords:
                if keyword in content:
                    status = keyword; css_class = "road-red"; is_high_risk = True; break
            if not is_high_risk:
                for keyword in mid_risk_keywords:
                    if keyword in content:
                        status = keyword; css_class = "road-yellow"; break
            
            is_partial_closure = any(keyword in content for keyword in degree_keywords)
            has_downgrade_option = any(keyword in content for keyword in downgrade_keywords)
            if is_high_risk:
                if is_partial_closure:
                    status = f"ç®¡åˆ¶ ({status}å–®ç·š)"; css_class = "road-yellow"
                elif has_downgrade_option:
                    status = f"ç®¡åˆ¶ ({status}æ”¹é“)"; css_class = "road-yellow"

            road_name = news.get("RoadName")
            is_old_road_event = (road_name == 'å°9ä¸ç·š') or ("å°9ä¸ç·š" in content)
            
            classified = False
            for section_name, keywords in sections.items():
                if any(keyword in content for keyword in keywords):
                    results[section_name].append({
                        "section": section_name, "status": status, "class": css_class,
                        "desc": f"ï¼ˆ{content}ï¼‰", "time": report_time, "is_old_road": is_old_road_event,
                        "detail_url": news.get("NewsURL", "") # å¯ä»¥åŠ ä¸Šæ¶ˆæ¯çš„åŸå§‹ç¶²å€
                    })
                    classified = True
                    break
            
            if not classified:
                print(f"    [æœªåˆ†é¡æ¶ˆæ¯]: {content}")


    except requests.exceptions.RequestException as e:
        print(f"âŒ ç²å– TDX è·¯æ³è³‡æ–™å¤±æ•—: {e}")
        if e.response:
            print(f"    ä¼ºæœå™¨å›æ‡‰éŒ¯èª¤: {e.response.text}")
        error_event = { "section": "å…¨ç·š", "status": "è®€å–å¤±æ•—", "class": "road-red", "desc": "ç„¡æ³•é€£æ¥TDXè·¯æ³ä¼ºæœå™¨", "time": "", "is_old_road": False, "detail_url": "" }
        for section_name in sections.keys():
            results[section_name].append(error_event)
            
    return results

# --- FastAPI æ ¹è·¯ç”± (ä¿æŒä¸è®Š) ---
@app.get("/")
def read_root():
    return {"status": "Guardian Angel Dashboard FINAL VERSION is running."}

@app.head("/")
def read_root_head():
    return Response(status_code=200)
