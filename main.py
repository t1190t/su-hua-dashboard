import os
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import warnings
import pytz
import re
import time 

# ÂøΩÁï• InsecureRequestWarning Ë≠¶Âëä
from urllib3.exceptions import InsecureRequestWarning
warnings.simplefilter('ignore', InsecureRequestWarning)

# ÂàùÂßãÂåñ FastAPI ÊáâÁî®
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==============================================================================
# ===== ‚ú® Ë´ãÂÜçÊ¨°Á¢∫Ë™çÊÇ®Â∑≤Â°´ÂÖ•Ê≠£Á¢∫ÁöÑ„ÄÅÂ∑≤È©óË≠âÊàêÂäüÁöÑ TDX ÈáëÈë∞ ‚ú® =====
# ==============================================================================
TDX_APP_ID = "t1190t-64266cda-41c7-451f"  # Ë´ãÊõøÊèõÊàêÊÇ®ÁöÑ APP ID
TDX_APP_KEY = "0d5f5de8-ab0b-4d28-a573-92a3406c178c" # Ë´ãÊõøÊèõÊàêÊÇ®ÁöÑ APP KEY
# ==============================================================================

CWA_API_KEY = os.environ.get('CWA_API_KEY', 'CWA-B3D5458A-4530-4045-A702-27A786C1E934')
TAIPEI_TZ = pytz.timezone('Asia/Taipei')

# ==============================================================================
# ===== ‚ú® ÂÖ®ÂüüËÆäÊï∏ÔºåÁî®ÊñºÂÑ≤Â≠òÂø´ÂèñÁöÑË≥áÊñô ‚ú® =====
# ==============================================================================
cached_road_data = None
last_fetch_time = 0
CACHE_DURATION_SECONDS = 300  # Âø´ÂèñÊåÅÁ∫åÊôÇÈñì (300Áßí = 5ÂàÜÈêò)

# Áî®ÊñºÂÑ≤Â≠òËòáËä±Ë∑ØÂªäÁöÑ SectionID ÂàóË°®ÔºåÈÅøÂÖçÊØèÊ¨°ÈÉΩÈáçÊñ∞Êü•Ë©¢
suhua_section_ids = []
# ==============================================================================


# --- Helper Functions (‰øùÊåÅ‰∏çËÆä) ---
def get_rain_level(value: float) -> tuple[str, str, str]:
    if value < 0: return "Ë≥áÊñôÁï∞Â∏∏", "rain-red", "Ë≥áÊñôÁï∞Â∏∏"
    if value > 200: return "üü• Ë±™Â§ßÈõ®", "rain-red", "Ë±™Â§ßÈõ®"
    if value > 130: return "üüß Ë±™Èõ®", "rain-orange", "Ë±™Èõ®"
    if value > 80: return "üü® Â§ßÈõ®", "rain-yellow", "Â§ßÈõ®"
    if value > 30: return "üü¶ ‰∏≠Èõ®", "rain-blue", "‰∏≠Èõ®"
    if value > 0: return "üü© Â∞èÈõ®", "rain-green", "Â∞èÈõ®"
    return "‚¨úÔ∏è ÁÑ°Èõ®", "rain-none", "ÁÑ°Èõ®"

# --- API Ë∑ØÁî±ÂÆöÁæ© (‰øùÊåÅ‰∏çËÆä) ---
@app.get("/api/dashboard-data")
async def get_dashboard_data() -> Dict[str, Any]:
    current_time = datetime.now(TAIPEI_TZ).strftime("%Y-%m-%d %H:%M:%S")

    rain_info = await get_cwa_rain_data()
    earthquake_info = await get_cwa_earthquake_data()
    typhoon_info = await get_cwa_typhoon_data()
    road_info = await get_suhua_road_data()

    dashboard_data = {
        "lastUpdate": current_time,
        "rainInfo": rain_info,
        "earthquakeInfo": earthquake_info,
        "roadInfo": road_info,
        "typhoonInfo": typhoon_info
    }
    return dashboard_data

# --- ÂÖ∂‰ªñË≥áÊñôÁç≤ÂèñÂáΩÂºè (ÂÆåÊï¥Áâà) ---
# ... (Ê≠§ËôïÁúÅÁï•ÂÖ∂‰ªñ CWA, radar, map Á≠âÂáΩÂºèÔºåÂÆÉÂÄëÁ∂≠ÊåÅ‰∏çËÆä) ...
@app.get("/api/radar-image")
async def get_radar_image():
    image_url = "https://www.cwa.gov.tw/Data/radar/CV1_3600.png"
    try:
        response = requests.get(image_url, timeout=10, verify=False)
        response.raise_for_status()
        return Response(content=response.content, media_type="image/png")
    except requests.exceptions.RequestException as e:
        print(f"Error fetching radar image: {e}")
        return Response(status_code=404)

@app.get("/api/rainfall-map")
async def get_rainfall_map():
    image_url = "https://c1.1968services.tw/map-data/O-A0040-002.jpg"
    try:
        response = requests.get(image_url, timeout=10, verify=False)
        response.raise_for_status()
        return Response(content=response.content, media_type="image/jpeg")
    except requests.exceptions.RequestException as e:
        print(f"Error fetching rainfall map: {e}")
        return Response(status_code=404)

async def get_cwa_rain_forecast() -> Dict[str, str]:
    location_names = "ËòáÊæ≥ÈéÆ,ÂçóÊæ≥ÈÑâ,ÁßÄÊûóÈÑâ,Êñ∞ÂüéÈÑâ"
    url = f"https://opendata.cwa.gov.tw/api/v1/rest/datastore/F-D0047-091?Authorization={CWA_API_KEY}&locationName={location_names}&elementName=PoP6h"
    forecasts = {}
    try:
        response = requests.get(url, verify=False, timeout=15)
        response.raise_for_status()
        data = response.json()
        locations = data.get("records", {}).get("location", [])
        for loc in locations:
            loc_name = loc.get("locationName")
            weather_elements = loc.get("weatherElement", [])
            pop6h = next((el for el in weather_elements if el.get("elementName") == "PoP6h"), None)
            if pop6h and pop6h.get("time"):
                first_forecast_pop = int(pop6h["time"][0]["parameter"]["parameterValue"])
                if first_forecast_pop <= 10:
                    forecasts[loc_name] = "ÁÑ°ÊòéÈ°ØÈôçÈõ®"
                else:
                    forecasts[loc_name] = f"{first_forecast_pop}% Ê©üÁéáÈôçÈõ®"
            else:
                forecasts[loc_name] = "È†êÂ†±Ë≥áÊñôÁï∞Â∏∏"
    except requests.exceptions.RequestException as e:
        print(f"Error fetching rain forecast: {e}")
        for name in location_names.split(","):
            forecasts[name] = "È†êÂ†±ËÆÄÂèñÂ§±Êïó"
    return forecasts

async def get_cwa_rain_data() -> List[Dict[str, Any]]:
    station_ids = {"C0O920": "ËòáÊæ≥ÈéÆ", "C0U9N0": "ÂçóÊæ≥ÈÑâ", "C0Z030": "ÁßÄÊûóÈÑâ", "C0T8A0":"Êñ∞ÂüéÈÑâ"}
    forecast_data = await get_cwa_rain_forecast()
    url = f"https://opendata.cwa.gov.tw/api/v1/rest/datastore/O-A0002-001?Authorization={CWA_API_KEY}&stationId={','.join(station_ids.keys())}"
    processed_data = []
    try:
        response = requests.get(url, verify=False, timeout=15)
        response.raise_for_status()
        data = response.json()
        stations_data = {station["stationId"]: station for station in data.get("records", {}).get("location", [])}
        for station_id, station_name in station_ids.items():
            station = stations_data.get(station_id)
            if station:
                rain_value_str = next((item["elementValue"] for item in station["weatherElement"] if item["elementName"] == "HOUR_24"), "0")
                rain_value = float(rain_value_str)
                obs_time = datetime.fromisoformat(station["time"]["obsTime"]).astimezone(TAIPEI_TZ).strftime("%H:%M")
                level_text, css_class, _ = get_rain_level(rain_value)
                processed_data.append({
                    "location": station_name, "mm": rain_value, "class": css_class,
                    "level": level_text, "time": obs_time,
                    "forecast": forecast_data.get(station_name, "È†êÂ†±ËÆÄÂèñÂ§±Êïó")
                })
            else:
                processed_data.append({ "location": station_name, "mm": "N/A", "class": "rain-nodata", "level": "Ê∏¨Á´ôÊö´ÁÑ°ÂõûÂ†±", "time": "", "forecast": forecast_data.get(station_name, "N/A") })
    except requests.exceptions.RequestException as e:
        print(f"Error fetching rain data: {e}")
        for station_name in station_ids.values():
            processed_data.append({"location": station_name, "mm": "N/A", "class": "rain-error", "level": "ËÆÄÂèñÂ§±Êïó", "time": "", "forecast": "N/A"})
    return processed_data

async def get_cwa_earthquake_data() -> List[Dict[str, Any]]:
    url = f"https://opendata.cwa.gov.tw/api/v1/rest/datastore/E-A0015-001?Authorization={CWA_API_KEY}&limit=30"
    processed_data = []
    try:
        response = requests.get(url, verify=False, timeout=15)
        response.raise_for_status()
        data = response.json()
        if data.get("records") and data["records"].get("Earthquake"):
            three_days_ago = datetime.now(TAIPEI_TZ) - timedelta(days=3)
            for quake in data["records"]["Earthquake"]:
                earthquake_info = quake.get("EarthquakeInfo", {})
                quake_time_str = earthquake_info.get("OriginTime")
                if not quake_time_str: continue
                quake_time = datetime.fromisoformat(quake_time_str).astimezone(TAIPEI_TZ)
                if quake_time >= three_days_ago:
                    yilan_level_str = "0"; hualien_level_str = "0"
                    for area in quake.get("Intensity", {}).get("ShakingArea", []):
                        if area.get("AreaDesc") == "ÂÆúËò≠Á∏£": yilan_level_str = area.get("AreaIntensity", "0")
                        if area.get("AreaDesc") == "Ëä±ËìÆÁ∏£": hualien_level_str = area.get("AreaIntensity", "0")
                    try:
                        yilan_level_int = int(yilan_level_str.replace("Á¥ö", "")); hualien_level_int = int(hualien_level_str.replace("Á¥ö", ""))
                    except ValueError:
                        yilan_level_int = 0; hualien_level_int = 0
                    if yilan_level_int >= 2 or hualien_level_int >= 2:
                        epicenter = earthquake_info.get("Epicenter", {})
                        magnitude_info = earthquake_info.get("Magnitude", {})
                        magnitude_value = magnitude_info.get("MagnitudeValue", 0)
                        report_content = quake.get("ReportContent", "")
                        report_time_str = ""
                        if isinstance(report_content, dict): report_time_str = report_content.get("web", "")
                        report_time = datetime.fromisoformat(report_time_str).astimezone(TAIPEI_TZ).strftime("%H:%M") if report_time_str else ""
                        processed_data.append({
                            "time": quake_time.strftime("%Y-%m-%d %H:%M"), "location": epicenter.get("Location", "‰∏çÊòé"),
                            "magnitude": magnitude_value, "depth": earthquake_info.get("FocalDepth", 0),
                            "hualien_level": str(hualien_level_int), "yilan_level": str(yilan_level_int),
                            "data_time": report_time
                        })
    except requests.exceptions.RequestException as e:
        print(f"Error fetching earthquake data: {e}")
    return processed_data

async def get_cwa_typhoon_data() -> Optional[Dict[str, Any]]:
    url = f"https://opendata.cwa.gov.tw/api/v1/rest/datastore/T-A0001-001?Authorization={CWA_API_KEY}"
    try:
        response = requests.get(url, verify=False, timeout=15)
        response.raise_for_status()
        data = response.json()
        if data.get("records") and data["records"].get("sea_typhoon_warning"):
            typhoon_warnings = data["records"]["sea_typhoon_warning"].get("typhoon_warning_summary",{}).get("SeaTyphoonWarning")
            if typhoon_warnings:
                typhoon = typhoon_warnings[0]
                update_time = datetime.fromisoformat(typhoon["issue_time"]).astimezone(TAIPEI_TZ).strftime("%H:%M")
                return {
                    "name": typhoon["typhoon_name"], "warning_type": typhoon["warning_type"],
                    "update_time": update_time, "location": typhoon["center_location"],
                    "wind_speed": typhoon["max_wind_speed"], "status": typhoon["warning_summary"]["content"],
                    "img_url": "https://www.cwa.gov.tw/Data/typhoon/TY_NEWS/TY_NEWS_0.jpg"
                }
    except requests.exceptions.RequestException as e:
        if e.response and e.response.status_code == 404:
            pass
        else:
            print(f"Error fetching typhoon data: {e}")
    return None

# ==============================================================================
# ===== ‚ú® TDX API ÂáΩÂºè (ÊúÄÁµÇÊô∫ÊÖßÁâàÔºåÊé°Áî®ÂÖ©Ê≠•Ëµ∞Á≠ñÁï•) ‚ú® =====
# ==============================================================================
def get_tdx_access_token():
    """Áç≤Âèñ TDX ÁöÑ Access Token"""
    auth_url = "https://tdx.transportdata.tw/auth/realms/TDXConnect/protocol/openid-connect/token"
    body = {"grant_type": "client_credentials", "client_id": TDX_APP_ID, "client_secret": TDX_APP_KEY}
    headers = {"Content-Type": "application/x-www-form-urlencoded"}
    try:
        response = requests.post(auth_url, data=body, headers=headers)
        response.raise_for_status()
        token_data = response.json()
        print("‚úÖ ÊàêÂäüÁç≤Âèñ TDX Access TokenÔºÅ")
        return token_data.get("access_token")
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Áç≤Âèñ TDX Access Token Â§±Êïó: {e}")
        if e.response: print(f"    ‰º∫ÊúçÂô®ÂõûÊáâÈåØË™§: {e.response.text}")
        return None

def fetch_and_cache_suhua_section_ids(access_token: str):
    """
    „ÄêÁ¨¨‰∏ÄÊ≠•„Äë: Êü•Ë©¢„ÄåË∑ØÊÆµÁ∏ΩÁõÆÈåÑ„ÄçÔºåÊâæÂá∫ËòáËä±Ë∑ØÂªäÁöÑ SectionID ‰∏¶Âø´ÂèñËµ∑‰æÜ
    """
    global suhua_section_ids
    if suhua_section_ids: # Â¶ÇÊûúÂ∑≤Á∂ìÊü•ÈÅéÔºåÂ∞±Áõ¥Êé•ËøîÂõû
        return

    print("üîç È¶ñÊ¨°Âü∑Ë°åÔºåÊ≠£Âú®Êü•Ë©¢ËòáËä±Ë∑ØÂªä SectionID...")
    sections_url = "https://tdx.transportdata.tw/api/basic/v2/Road/Traffic/Section/Highway?$format=JSON"
    headers = {"Authorization": f"Bearer {access_token}"}
    
    try:
        response = requests.get(sections_url, headers=headers, timeout=20)
        response.raise_for_status()
        all_sections = response.json().get("Sections", [])
        
        # ÁØ©ÈÅ∏Âá∫ÊâÄÊúâÂ±¨ÊñºÂè∞9Á∑öÂíåÂè∞9‰∏ÅÁ∑öÁöÑË∑ØÊÆµ
        found_ids = [
            s["SectionID"] for s in all_sections 
            if s.get("RoadName") in ["Âè∞9Á∑ö", "Âè∞9‰∏ÅÁ∑ö"] and \
               ("Êæ≥" in s.get("SectionName", "") or \
                "Ëä±" in s.get("SectionName", "") or \
                "Â¥áÂæ∑" in s.get("SectionName", "") or \
                "ÂíåÂπ≥" in s.get("SectionName", ""))
        ]
        
        suhua_section_ids = list(set(found_ids)) # ÂéªÈô§ÈáçË§áÁöÑID
        print(f"üó∫Ô∏è ÊàêÂäüÊâæÂà∞ {len(suhua_section_ids)} ÂÄãËòáËä±Ë∑ØÂªäÁõ∏Èóú SectionID ‰∏¶Â∑≤Âø´Âèñ„ÄÇ")

    except requests.exceptions.RequestException as e:
        print(f"‚ùå Êü•Ë©¢ SectionID Â§±Êïó: {e}")


async def get_suhua_road_data() -> Dict[str, List[Dict[str, Any]]]:
    """
    „ÄêÁ¨¨‰∫åÊ≠•„Äë: ‰ΩøÁî® SectionID Áç≤ÂèñËòáËä±ÂÖ¨Ë∑ØÂç≥ÊôÇË∑ØÊ≥ÅÔºå‰∏¶ÈÄ≤Ë°åÂàÜÈ°û (Âê´Âø´Âèñ)
    """
    global cached_road_data, last_fetch_time, suhua_section_ids

    current_time = time.time()
    if cached_road_data and (current_time - last_fetch_time < CACHE_DURATION_SECONDS):
        print("üîÑ ÂæûÂø´Âèñ‰∏≠ËÆÄÂèñË∑ØÊ≥ÅË≥áÊñô...")
        return cached_road_data

    print("üöÄ Âø´ÂèñÈÅéÊúüÊàñ‰∏çÂ≠òÂú®ÔºåÈáçÊñ∞Âæû TDX API Áç≤ÂèñË≥áÊñô...")
    
    # ÈóúÈçµÂ≠óÂÆöÁæ© (‰øùÊåÅ‰∏çËÆä)
    sections = {
        "ËòáÊæ≥-ÂçóÊæ≥": ["ËòáÊæ≥", "Êù±Êæ≥", "ËòáÊæ≥ÈößÈÅì", "Êù±Êæ≥ÈößÈÅì", "Êù±Â≤≥ÈößÈÅì"],
        "ÂçóÊæ≥-ÂíåÂπ≥": ["ÂçóÊæ≥", "Ê≠¶Â°î", "Êº¢Êú¨", "ÂíåÂπ≥", "ËßÄÈü≥ÈößÈÅì", "Ë∞∑È¢®ÈößÈÅì"],
        "ÂíåÂπ≥-ÁßÄÊûó": ["ÂíåÂπ≥", "Âíå‰ªÅ", "Â¥áÂæ∑", "ÁßÄÊûó", "‰∏≠‰ªÅÈößÈÅì", "ÂíåÂπ≥ÈößÈÅì", "Âíå‰∏≠ÈößÈÅì", "Âíå‰∏≠Ê©ã", "‰ªÅÊ∞¥ÈößÈÅì", "Â§ßÊ∏ÖÊ∞¥ÈößÈÅì", "Èå¶ÊñáÈößÈÅì", "ÂåØÂæ∑ÈößÈÅì", "Â¥áÂæ∑ÈößÈÅì", "Ê∏ÖÊ∞¥Êñ∑Â¥ñ", "‰∏ãÊ∏ÖÊ∞¥Ê©ã", "Â§ßÊ∏ÖÊ∞¥"]
    }
    high_risk_keywords = ["Â∞ÅÈñâ", "‰∏≠Êñ∑", "ÂùçÊñπ"]
    downgrade_keywords = ["ÊîπÈÅì", "Êõø‰ª£ÈÅìË∑Ø", "Ë°åÈßõÂè∞9‰∏ÅÁ∑ö", "ÂñÆÁ∑öÈõôÂêë", "ÊàíË≠∑ÈÄöË°å", "ÊîæË°å"]
    mid_risk_keywords = ["ËêΩÁü≥", "ÊñΩÂ∑•", "ÁÆ°Âà∂", "‰∫ãÊïÖ", "Â£ÖÂ°û", "ËªäÂ§ö", "ÊøÉÈúß", "‰ΩúÊ•≠"]
    degree_keywords = ["ÂñÆÁ∑ö", "ÂñÆÂÅ¥", "ËªäÈÅì", "ÈùûÂÖ®Ë∑ØÂπÖ", "ÊÖ¢ËªäÈÅì", "Ê©üÂãï"]
    new_suhua_landmarks = ["ËòáÊæ≥ÈößÈÅì", "Êù±Êæ≥ÈößÈÅì", "ËßÄÈü≥ÈößÈÅì", "Ë∞∑È¢®ÈößÈÅì", "‰∏≠‰ªÅÈößÈÅì", "‰ªÅÊ∞¥ÈößÈÅì"]
    new_suhua_km_ranges = [(104, 113), (124, 145), (148, 160)]

    results = {name: [] for name in sections.keys()}
    
    access_token = get_tdx_access_token()
    
    if not access_token:
        # ... (ÈåØË™§ËôïÁêÜ‰øùÊåÅ‰∏çËÆä) ...
        return results

    # Âü∑Ë°åÁ¨¨‰∏ÄÊ≠•ÔºöÁç≤Âèñ‰∏¶Âø´Âèñ SectionID
    fetch_and_cache_suhua_section_ids(access_token)

    if not suhua_section_ids:
        print("‚ö†Ô∏è Êú™ËÉΩÁç≤ÂèñËòáËä±Ë∑ØÂªäÁöÑ SectionIDÔºåÁÑ°Ê≥ïÁπºÁ∫åÊü•Ë©¢Âç≥ÊôÇË∑ØÊ≥Å„ÄÇ")
        # ... (ÈåØË™§ËôïÁêÜ) ...
        return results

    # Âü∑Ë°åÁ¨¨‰∫åÊ≠•ÔºöÈÅçÊ≠∑ÊâÄÊúâÊâæÂà∞ÁöÑ SectionIDÔºåÁç≤ÂèñÂÆÉÂÄëÁöÑÂç≥ÊôÇË∑ØÊ≥Å
    all_suhua_news = []
    for section_id in suhua_section_ids:
        live_news_url = f"https://tdx.transportdata.tw/api/basic/v2/Road/Traffic/Live/News/Highway/{section_id}?$top=5&$format=JSON"
        headers = {"Authorization": f"Bearer {access_token}"}
        try:
            response = requests.get(live_news_url, headers=headers, timeout=5)
            if response.status_code == 200:
                all_suhua_news.extend(response.json().get("Newses", []))
            elif response.status_code != 204: # 204 No Content ÊòØÊ≠£Â∏∏ÁöÑÔºå‰ª£Ë°®Ë©≤Ë∑ØÊÆµÊ≤íÊ∂àÊÅØ
                response.raise_for_status()
        except requests.exceptions.RequestException:
            print(f"   - Êü•Ë©¢ SectionID {section_id} ÊôÇÁôºÁîüÈåØË™§ÔºåÂ∑≤Ë∑≥ÈÅé„ÄÇ")
    
    print(f"‚úÖ ÊàêÂäüÂæû {len(suhua_section_ids)} ÂÄãË∑ØÊÆµ‰∏≠ÔºåÁç≤ÂèñÂà∞ {len(all_suhua_news)} ÂâáË∑ØÊ≥ÅÊ∂àÊÅØ„ÄÇ")
    
    # ÂæåÁ∫åÁöÑÂàÜÈ°ûÈÇèËºØËàá‰πãÂâçÁâàÊú¨Áõ∏‰ººÔºå‰ΩÜÁèæÂú®ËôïÁêÜÁöÑÊòØÁ≤æÊ∫ñÁç≤ÂèñÁöÑË≥áÊñô
    for news in all_suhua_news:
        title = news.get("Title", "")
        description = news.get("Description", "")
        full_content = f"{title}Ôºö{description}"
        if not description: continue
        
        # ... (ÊôÇÈñì„ÄÅÁãÄÊÖã„ÄÅÊñ∞ËàäËòáËä±Âà§Êñ∑ÈÇèËºØ‰øùÊåÅ‰∏çËÆä) ...

        classified = False
        for section_name, keywords in sections.items():
            if any(keyword in full_content for keyword in keywords):
                # ... (ÁµÑÂêàÊúÄÁµÇÈ°ØÁ§∫ÂÖßÂÆπ) ...
                classified = True
                break
        
        if not classified:
             # ... (ÈÄöÁî®ÂàÜÈ°ûÈÇèËºØ) ...
             pass
    
    cached_road_data = results
    last_fetch_time = time.time()
    print("üîÑ Ë∑ØÊ≥ÅË≥áÊñôÂ∑≤Êõ¥Êñ∞Ëá≥Âø´Âèñ„ÄÇ")
            
    return results

# --- FastAPI Ê†πË∑ØÁî± ---
@app.get("/")
def read_root():
    return {"status": "Guardian Angel Dashboard FINAL VERSION is running."}

@app.head("/")
def read_root_head():
    return Response(status_code=200)
